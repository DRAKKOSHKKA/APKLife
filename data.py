import requests
from bs4 import BeautifulSoup

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
BASE_URL = "https://it-institut.ru/Raspisanie/SearchedRaspisanie"
GROUP_NAME = "11 –Ω–º–æ"
SEARCH_ID = "34745"
OWNER_ID = "37"
WEEK_ID = "14441"

params = {
    "SearchId": SEARCH_ID,
    "SearchString": GROUP_NAME,
    "Type": "Group",
    "OwnerId": OWNER_ID,
    "WeekId": WEEK_ID
}

response = requests.get(BASE_URL, params=params)
response.encoding = "utf-8"

if response.status_code != 200:
    print("–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞:", response.status_code)
    exit()

soup = BeautifulSoup(response.text, "html.parser")
table = soup.find("table")

if not table:
    print("–¢–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
    exit()

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã ===
rows = table.find_all("tr")
days = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞"]

parsed = {}
current_day = "–ë–µ–∑ –¥–Ω—è"  # ‚Üê –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

for row in rows:
    cols = [td.get_text(strip=True) for td in row.find_all("td")]
    if not any(cols):
        continue

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏
    if len(cols) == 1 and cols[0] in days:
        current_day = cols[0]
        parsed.setdefault(current_day, [])
        continue

    # –ï—Å–ª–∏ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ —É—Ä–æ–∫
    parsed.setdefault(current_day, [])
    parsed[current_day].append([col for col in cols if col])

# === –í—ã–≤–æ–¥ ===
for day, lessons in parsed.items():
    print(f"\nüìÖ {day}")
    for i, cols in enumerate(lessons, 1):
        print(f"  {i}. {' | '.join(cols)}")
